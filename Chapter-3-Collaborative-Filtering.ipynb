{
 "metadata": {
  "name": "Chapter-3-Collaborative-Filtering"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Chapter 3 - Collaborative Filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Implicit ratings and item based filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In chapter 2 we learned the basics of collaborative filtering and recommendation systems. \n",
      "The algorithms described in that chapter are general purpose and could be used with a \n",
      "variety of data. Users rated different items on a five or ten point scale and the algorithms \n",
      "found other users who had similar ratings. As was mentioned, there is some evidence to \n",
      "suggest users typically do not use this fine-grain distinction and instead tend to either give \n",
      "the top rating or the lowest one. This all-or-nothing rating strategy can sometimes lead to \n",
      "unusable results. In this chapter we will examine ways to fine tune collaborative filtering to \n",
      "produce more accurate recommendations in an efficient manner."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Explicit ratings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way of distinguishing types of user preferences is whether they are explicit or implicit. \n",
      "Explicit ratings are when the user herself explicitly rates the item. One example of this is the \n",
      "thumbs up / thumbs down rating on sites such as Pandora and YouTube."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Implicit Ratings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For implicit ratings, we don't ask users to give any ratings\u2014we just observe their behavior. \n",
      "An example of this is keeping track of what a user clicks on in the online New York Times."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After observing what a user clicks on for a few weeks you can imagine that we could develop a reasonable profile of that user\u2014she doesn't like sports but seems to like technology news. If the user clicks on the article \u201cFastest Way to Lose Weight Discovered by Professional Trainers\u201d \n",
      "and the article \u201cSlow and Steady: How to lose weight and keep it off\u201d perhaps she wishes to lose weight. If she clicks on the iPhone ad, she perhaps has an interest in that product. (By the way, the term used when a user clicks on an ad is called 'click through'.) Consider what information we can gain from recording what products a user clicks on in Amazon On your peronalized Amazon front page this information is displayed:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, Amazon keeps track of what people click on. It knows, for example, that people who viewed the book Jupiter\u2019s Travels: Four years around the world on a Triumph \n",
      "also viewed the DVD Long Way Round, which chronicles the actor Ewan McGregor as he travels with his mate around the world on motorcycles. As can be seen in the Amazon \n",
      "screenshot above, this information is used to display the items in the section \u201cCustomers who viewed this also viewed.\u201d \n",
      "Another implicit rating is what the customer actually buys. Amazon also keeps track of this information and uses it for their recommendations \u201cFrequently Bought Together\u201d and \u201cCustomers Who Viewed This Item Also Bought\u201d:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You would think that \u201cFrequently Bought Together\u201d would lead to some unusual recommendations but this works surprisingly well. Imagine what information a program can acquire by monitoring your behavior in iTunes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, there's the fact that I added a song to iTunes. That indicates minimally that I was \n",
      "interested enough in the song to do so. Then there is the Play Count information. In the \n",
      "image above, I've listened to Zee Avi's \u201cAnchor\u201d 52 times. That suggests that I like that song \n",
      "(and in fact I do). If I have a song in my library for awhile and only listened to it once, that \n",
      "might indicate that I don't like the song."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Problems with explicit ratings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Problem 1: People are lazy and don't rate items."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, users will typically not bother to rate items. I imagine \n",
      "most of you have bought a substantial amount of stuff on \n",
      "Amazon. I know I have. In the last month I bought a \n",
      "microHelicopter, a 1TB hard drive, a USB-SATA converter, \n",
      "a bunch of vitamins, two Kindle books (Murder City: \n",
      "Ciudad Juarez and the Global Economy's New Killing \n",
      "Fields and Ready Player One) and the physical books No \n",
      "Place to Hide, Dr. Weil's 8 Weeks to Optimum Health, \n",
      "Anticancer: A new way of life, and Rework. That's twelve \n",
      "items. How many have I rated? Zero. I imagine most of \n",
      "you are the same. You don't rate the items you buy. \n",
      "I have a gimp knee. I like hiking in the mountains and as a \n",
      "result own a number of trekking poles including some \n",
      "cheap ones I bought on Amazon that have taken a lot of \n",
      "abuse. Last year I flew to Austin for the 3 day Austin City \n",
      "Limits music festival. I aggravated my knee injury dashing \n",
      "from one flight to another and ended up going to REI to \n",
      "buy a somewhat pricey REI branded trekking pole. It broke \n",
      "in less than a day of walking on flat grass at a city park. \n",
      "Here I own $10 poles that don't break during constant use \n",
      "of hiking around in the Rockies and this pricey model \n",
      "broke on flat ground. At the time of the festival, as I was \n",
      "fuming, I planned to rate and write a review of the pole on \n",
      "the REI site. Did I? No, I am too lazy. So even in this \n",
      "extreme case I didn't rate the item. I think there are a lot of \n",
      "lazy people like me. People in general are too lazy or \n",
      "unmotivated to rate products."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Problem 2: People may lie or give only partial information."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say someone gets over that initial laziness and actually rates a product. That person may \n",
      "lie. This is illustrated in the drawing a few pages back. They can lie directly\u2014giving \n",
      "inaccurate ratings or lie via omission\u2014providing only partial information. Ben goes on a first \n",
      "date with Ann to see the 2010 Cannes Film Festival Winner, a Thai film, Uncle Boonmee \n",
      "Who Can Recall His Past Lives. They go with Ben's friend Dan and Dan's friend Clara. Ben \n",
      "thinks it was the worst film he ever saw. All the others absolutely loved it and gushed about it \n",
      "afterwards at the restaurant. It would not be surprising if Ben upped his rating of the film on \n",
      "online rating sites that his friends might see or just not rate the film."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Problem 3: People don't update their ratings."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose I am motivated by writing this chapter to rate my Amazon purchases. That 1TB hard \n",
      "drive works well\u2014it's very speedy and also very quiet. I rate it five stars. That \n",
      "microHelicopter is great. It is easy to fly and great fun and it survived multiple crashes. I rate \n",
      "it five stars. A month goes by. The hard drive dies and as a result I lose all my downloaded \n",
      "movies and music\u2014a major bummer. The microHelicopter suddenly stops working\u2014it looks \n",
      "like the motor is fried. Now I think both products suck. Chances are pretty good that I will \n",
      "not go to Amazon and update my ratings (laziness again). People still think I would rate both \n",
      "5 stars. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider Mary, a college student. For some reason, she loves giving Amazon ratings. Ten \n",
      "years ago she rated her favorite music albums with five stars: Giggling and Laughing: Silly \n",
      "Songs for Kids, and Sesame Songs: Sing Yourself Silly! Her most recent ratings included 5 \n",
      "stars for Wolfgang Amadeus Phoenix and The Twilight Saga: Eclipse Soundtrack. Based on \n",
      "these recent ratings she ends up being the closest neighbor to another college student Jen. It \n",
      "would be odd to recommend Giggling and Laughing: Silly Songs for Kids to Jen. This is a \n",
      "slightly different type of update problem than the one above, but a problem none-the-less."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A few pages ago I gave a list of items I bought at Amazon in the last month. It turns out I \n",
      "bought two of those items for other people. I bought the anticancer book for my cousin and \n",
      "the Rework book for my son. To see why this is a problem, let me come up with a more \n",
      "compelling example by going further back in my purchase history. I bought some kettlebells \n",
      "and the book Enter the Kettlebell! Secret of the Soviet Supermen as a gift for my son and a \n",
      "Plush Chase Border Collie stuffed animal for my wife because our 14-year-old border collie \n",
      "died. Using purchase history as an implicit rating of what a person likes, might lead you to \n",
      "believe that people who like kettlebells, like stuffed animals, like microHelicopters, books on \n",
      "anticancer, and the book Ready Player One. Amazon's purchase history can't distinguish \n",
      "between purchases for myself and purchases I make as gifts. Stephen Baker describes a \n",
      "related example:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we are attempting to build a profile of a person\u2014what a particular person likes\u2014this dog \n",
      "collar purchase is problematic.\n",
      "Finally, consider a couple sharing a Netflix account. He likes action flicks with lots of \n",
      "explosions and helicopters; she likes intellectual movies and romantic comedies. If we just \n",
      "look at rental history, we build an odd profile of someone liking two very different things.\n",
      "Recall that I said my purchase of the book Anticancer: A New Way of Life was as a gift to my \n",
      "cousin. If we mine my purchase history a bit more we would see that I bought this book \n",
      "before. In fact, in the last year I purchased multiple copies of three books. One can imagine \n",
      "that I am making these multiple purchases not because I am losing the books, or that I am \n",
      "losing my mind and forgetting that I read the books. The most rational reason, is that I liked \n",
      "the books so much I am in a sense recommending these books to others by giving them as \n",
      "gifts. So we can gain a substantial amount of information from a person's purchase history. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keep in mind that the algorithms described in chapter 2 can be used regardless of whether \n",
      "the data is explicit or implicit."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###The problems of success"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You have a successful streaming music service with a built in recommendation system. What \n",
      "could possibly go wrong? \n",
      "Suppose you have one million users. Every time you want to make a recommendation for \n",
      "someone you need to calculate one million distances (comparing that person to the 999,999 \n",
      "other people). If we are making multiple recommendations per second, the number of \n",
      "calculations get extreme. Unless you throw a lot of iron at the problem the system will get \n",
      "slow. To say this in a more formal way, latency can be a major drawback of neighbor-based \n",
      "kImplicit Data: \n",
      "Web pages: clicking on the link to a page\n",
      " time spent looking at a page\n",
      " repeated visits\n",
      " referring a page to others\n",
      " what a person watches on Hulu\n",
      "Music players: what the person plays\n",
      " skipping tunes\n",
      " number of times a tune is played\n",
      "This just scratches the surface! r\u0000ecommendation systems. Fortunately, there is a solution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###User-based filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far we have been doing user-based collaborative filtering. We are comparing a user with \n",
      "every other user to find the closest matches. There are two main problems with this \n",
      "approach:\n",
      "1. Scalability. As we have just discussed, the computation increases as the number of \n",
      "users increases. User-based methods work fine for thousands of users, but scalability gets \n",
      "to be a problem when we have a million users.\n",
      "2. Sparsity. Most recommendation systems have many users and many products but the \n",
      "average user rates a small fraction of the total products. For example, Amazon carries \n",
      "millions of books but the average user rates just a handful of books. Because of this the \n",
      "algorithms we covered in chapter 2 may not find any nearest neighbors.\n",
      "Because of these two issues it might be better to do what is called item-based filtering."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Item-based filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose I have an algorithm that identifies products that are most similar to each other. For \n",
      "example, such an algorithm might find that Phoenix's album Wolfgang Amadeus Phoenix is \n",
      "similar to Passion Pit's album, Manners. If a user rates Wolfgang Amadeus Phoenix highly \n",
      "we could recommend the similar album Manners. Note that this is different than what we \n",
      "did for user-based filtering. In user-based filtering we had a user, found the most similar \n",
      "person (or users) to that user and used the ratings of that similar person to make \n",
      "recommendations. In item-based filtering, ahead of time we find the most similar items, and \n",
      "combine that with a user's rating of items to generate a recommendation. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Can you give me an example?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose our streaming music site has m users and n bands, where the users rate bands. This \n",
      "is shown in the following table. As before, the rows represent the users and the columns \n",
      "represent bands"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to compute the similarity of Phoenix to Passion Pit. To do this we only use \n",
      "users who rated both bands as indicated by the blue squares. If we were doing user-based \n",
      "filtering we would determine the similarity between rows. For item-based filtering we are \n",
      "determining the similarity between columns\u2014in this case between the Phoenix and Passion \n",
      "Pit columns. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Adjusted Cosine Similarity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To compute the similarity between items we will use Cosine Similarity which was introduced \n",
      "in chapter 2. We also already talked about grade inflation where a user gives higher ratings \n",
      "than expected. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To compensate for this grade inflation we will subtract the user's average rating from each \n",
      "rating. This gives us the adjusted cosine similarity formula shown here:\n",
      "s(i, j)=\n",
      "(Ru,i\n",
      "\u2212 Ru )(Ru,j\n",
      "\u2212 Ru )\n",
      "u\u2208U\n",
      "\u2211\n",
      "(Ru,i\n",
      "\u2212 Ru )\n",
      "2\n",
      "u\u2208U\n",
      "\u2211 (Ru,j\n",
      "\u2212 Ru )\n",
      "2\n",
      "u\u2208U\n",
      "\u2211\n",
      "This formula is from a seminal article in collaborative filtering: \u201cItem-based collaborative \n",
      "filtering recommendation algorithms\u201d by Badrul Sarwar, George Karypis, Joseph Konstan, \n",
      "and John Reidl (http://www.grouplens.org/papers/pdf/www10_sarwar.pdf) \n",
      "(\n",
      "Ru,i\n",
      "\u2212 Ru )\n",
      "means the rating R user u gives to item i minus the average rating that user gave for all items \n",
      "she rated. This gives us the normalized rating. In the formula above for s(i,j) we are finding \n",
      "the similarity between items i and j. The numerator says that for every user who rated both \n",
      "items multiply the normalized rating of those two items and sum the results. In the \n",
      "denominator we sum the squares of all the normalized ratings for item i and then take the \n",
      "square root of that result. We do the same for item j. And then we multiply those two \n",
      "together.\n",
      "To illustrate adjusted cosine similarity we will use the sample data described above and \n",
      "reprinted on the following page. The column, average rating is the average rating given \n",
      "by that user."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Slope One"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another popular algorithm for item-based collaborative filtering is Slope One. A major \n",
      "advantage of Slope One is that it is simple and hence easy to implement. Slope One was \n",
      "introduced in the paper \u201cSlope One Predictors for Online Rating-Based Collaborative \n",
      "Filtering\u201d by Daniel Lemire and Anna Machlachlan (http://www.daniel-lemire.com/fr/\n",
      "abstracts/SDM2005.html). This is an awesome paper and well worth the read. \n",
      "Here's the basic idea in a minimalist nutshell. Suppose Amy gave a rating of 3 to PSY and a \n",
      "rating of 4 to Whitney Houston. Ben gave a rating of 4 to PSY. We'd like to predict how Ben \n",
      "would rate Whitney Houston. In table form the problem might look like this:\n",
      "PSY Whitney Houston\n",
      "Amy\n",
      "Ben\n",
      "3 4\n",
      "4 ?\n",
      "To guess what Ben might rate Whitney Houston we could reason as follows. Amy rated \n",
      "Whitney one whole point better than PSY. We can predict then than Ben would rate Whitney \n",
      "one point higher so we will predict that Ben will give her a '5'. \n",
      "There are actually several Slope One algorithms. I will present the Weighted Slope One \n",
      "algorithm. Remember that a major advantage is that the approach is simple. What I present \n",
      "may look complex, but bear with me and things should become clear. You can consider Slope \n",
      "One to be in two parts. First, ahead of time (in batch mode, in the middle of the night or \n",
      "whenever) we are going to compute what is called the deviation between every pair of items. \n",
      "In the simple example above, this step will determine that Whitney is rated 1 better than PSY. \n",
      "Now we have a nice database of item deviations. In the second phase we actually make \n",
      "predictions. A user comes along, Ben for example. He has never heard Whitney Houston and \n",
      "we want to predict how he would rate her. Using all the bands he did rate along with our \n",
      "database of deviations we are going to make a prediction."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step is to compute the deviations. The average deviation of an item i with respect to \n",
      "item j is:\n",
      "devi,j\n",
      "=\n",
      "ui\n",
      "\u2212uj\n",
      "card(Si,j\n",
      "(X))\n",
      "u\u2208Si,j\n",
      "(X)\n",
      "\u2211\n",
      "where card(S) is how many elements are in S and X is the entire set of all ratings. So \n",
      "\n",
      "Part 1 (done ahead of time)\n",
      "Compute deviations between every \n",
      "pair of items\n",
      "Part 2\n",
      "Use deviations to make \n",
      "predictionscard(Sj,i(X)) is the number of people who have rated both j and i. Let's consider the deviation \n",
      "of PSY with respect to Taylor Swift. In this case, card(Sj,i(X)) is 2\u2014there are 2 people (Amy \n",
      "and Ben) who rated both Taylor Swift and PSY. The uj \u2013 ui numerator is (that user\u2019s rating \n",
      "for Taylor Swift) minus (that user\u2019s rating for PSY). So the deviation is:\n",
      "devswift,psy\n",
      "=\n",
      "(4\u2212 3)\n",
      "2\n",
      "+\n",
      "(5\u22122)\n",
      "2\n",
      "=\n",
      "1\n",
      "2\n",
      "+\n",
      "3\n",
      "2\n",
      "= 2\n",
      "So the deviation from PSY to Taylor Swift is 2 meaning that on average users rated Taylor \n",
      "Swift 2 better than PSY. What is the deviation from Taylor Swift to PSY?\n",
      "dev\n",
      "psy,swift\n",
      "=\n",
      "(3\u2212 4)\n",
      "2\n",
      "+\n",
      "(2\u22125)\n",
      "2\n",
      "= \u2212\n",
      "1\n",
      "2\n",
      "+\u2212\n",
      "3\n",
      "2\n",
      "= \u22122"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Part 2: Making predictions with Weighted Slope One\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay, so now we have a big collection of deviations. How can we use that collection to make \n",
      "predictions? As I mentioned, we are using Weighted Slope One or P\n",
      "wS1 --for Weighted Slope \n",
      "One Prediction. The formula is:\n",
      "P\n",
      "wS1\n",
      "(u)\n",
      "j\n",
      "=\n",
      "(devj,i\n",
      "+ui\n",
      "i\u2208S(u)\u2212{ j}\n",
      "\u2211 )cj,i\n",
      "cj,i\n",
      "i\u2208S(u)\u2212{ j}\n",
      "\u2211\n",
      "where \n",
      "cj,i\n",
      "= card(Sj,i\n",
      "(\u03c7))\n",
      "P\n",
      "wS1(u)j\n",
      "means our prediction using Weighted Slope One of user u\u2019s rating for item j. So, for \n",
      "example P\n",
      "wS1(Ben)Whitney Houston means our prediction for what Ben would rate Whitney \n",
      "Houston.\n",
      "Let's say I am interested in answering that question: How might Ben rate Whitney Houston?\n",
      "Let's dissect the numerator. \n",
      "i\u2208S(u)\u2212{ j}\n",
      "\u2211\n",
      "means for every musician that Ben has rated (except for Whitney Houston that is the {j} bit).\n",
      "The entire numerator means for every musician i that Ben has rated (except for Whitney \n",
      "Houston) we will look up the deviation of Whitney Houston to that musician and we will add \n",
      "that to Ben's rating for musician i. We multiply that by the cardinality of that pair\u2014the "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "number of people that rated both musicians (Whitney and musician i). \n",
      "Let's step through this:\n",
      "First, here are Ben\u2019s ratings and our deviations table from before:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Ben has rated Taylor Swift and gave her a 5\u2014that is the ui.\n",
      "2. The deviation of Whitney Houston with respect to Taylor Swift is -1 \u2014this is the devj,i.\n",
      "3. devj,i + ui then is 4.\n",
      "4. Looking at page 3-19 we see that there were two people (Amy and Daisy) that rated both \n",
      "Taylor Swift and Whitney Houston so cj,i = 2\n",
      "5. So (devj,i + ui\n",
      ") cj,i = 4 x 2 = 8\n",
      "6. Ben has rated PSY and gave him a 2.\n",
      "7. The deviation of Whitney Houston with respect to PSY is 0.75\n",
      "8. devj,i + ui then is 2.75\n",
      "9. Two people rated both Whitney Houston and PSY so (devj,i + ui\n",
      ") cj,i= 2.75 x 2 = 5.5\n",
      "10. We sum up steps 5 and 9 to get 13.5 for the numerator\n",
      "DENOMINATOR\n",
      "11. Dissecting the denominator we get something like for every musician that Ben has rated, \n",
      "sum the cardinalities of those musicians (how many people rated both that musician and"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Whitney Houston). So Ben has rated Taylor Swift and the cardinality of Taylor Swift and \n",
      "Whitney Houston (that is, the total number of people that rated both of them) is 2. Ben \n",
      "has rated PSY and his cardinality is also 2. So the denominator is 4.\n",
      "12. So our prediction of how well Ben will like Whitney Houston is 13.5\n",
      "4\n",
      "= 3.375"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Putting this into Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am going to extend the Python class developed in chapter 2. To save space I will not repeat \n",
      "the code for the recommender class here\u2014just refer back to it (and remember that you can \n",
      "download the code at http://guidetodatamining.com). Recall that the data for that class was \n",
      "in the following format:\n",
      "users2 = {\"Amy\": {\"Taylor Swift\": 4, \"PSY\": 3, \"Whitney Houston\": 4},\n",
      "\"Ben\": {\"Taylor Swift\": 5, \"PSY\": 2},\n",
      "\"Clara\": {\"PSY\": 3.5, \"Whitney Houston\": 4},\n",
      "\"Daisy\": {\"Taylor Swift\": 5, \"Whitney Houston\": 3}}\n",
      "First computing the deviations.\n",
      "Again, the formula for computing deviations is\n",
      "devi,j\n",
      "=\n",
      "ui\n",
      "\u2212uj\n",
      "card(Si,j\n",
      "(X))\n",
      "u\u2208Si,j\n",
      "(X)\n",
      "\u2211\n",
      "So the input to our computeDeviations function should be data in the format of users2 above. \n",
      "The output should be a representation of the following data:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number in the parentheses is the frequency (that is, the number of people that rated that \n",
      "pair of musicians). So for each pair of musicians we need to record both the deviation and the \n",
      "frequency. \n",
      "the pseudoCode for our function could be"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeDeviations(self):\n",
      "    for each i in bands:\n",
      "        for each j in bands:\n",
      "            if i \u2260 j:\n",
      "                compute dev(j,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-8-7a4f972a5e07>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-7a4f972a5e07>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for each i in bands:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That pseudocode looks pretty nice but as you can see, there is a disconnect between the data \n",
      "format expected by the pseudocode and the format the data is really in (see users2 above as \n",
      "an example). As code warriors we have two possibilities, either alter the format of the data, \n",
      "or revise the psuedocode. I am going to opt for the second approach. This revised pseudocode \n",
      "looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeDeviations(self):\n",
      "    for each person in the data:\n",
      "        get their ratings\n",
      "for each item & rating in that set of ratings:\n",
      "    for each item2 & rating2 in that set of ratings:\n",
      "        add the difference between the ratings to our computation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-9-d92560ad015f>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-d92560ad015f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for each person in the data:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Let's construct the method step-by-step\n",
      "Step 1:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeDeviations(self): \n",
      "# for each person in the data:\n",
      "# get their ratings \n",
      "for ratings in self.data.values():"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-10-0d0b8d91021f>, line 4)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python dictionaries (aka hash tables) are key value pairs. Self.data is a dictionary. The \n",
      "values method extracts just the values from the dictionary. Our data looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users2 = {\"Amy\": {\"Taylor Swift\": 4, \"PSY\": 3, \"Whitney Houston\": 4},\n",
      "          \"Ben\": {\"Taylor Swift\": 5, \"PSY\": 2},\n",
      "          \"Clara\": {\"PSY\": 3.5, \"Whitney Houston\": 4},\n",
      "          \"Daisy\": {\"Taylor Swift\": 5, \"Whitney Houston\": 3}}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 2:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeDeviations(self): \n",
      "    # for each person in the data: \n",
      "    # get their ratings \n",
      "    for ratings in self.data.values(): \n",
      "    #for each item & rating in that set of ratings: \n",
      "        for (item, rating) in ratings.items(): \n",
      "            self.frequencies.setdefault(item, {}) \n",
      "            self.deviations.setdefault(item, {})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the recommender class init method I initialized self.frequencies and self.deviations to be \n",
      "dictionaries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def __init__(self, data, k=1, metric='pearson', n=5):\n",
      "    ... \n",
      "    #\n",
      "    # The following two variables are used for Slope One\n",
      "    # \n",
      "    self.frequencies = {}\n",
      "    self.deviations = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Python dictionary method setdefault takes 2 arguments: a key and an initialValue. This \n",
      "method does the following. If the key does not exist in the dictionary it is added to the \n",
      "dictionary with the value initialValue. Otherwise it returns the current value of the key. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Step 3:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeDeviations(self): \n",
      "    # for each person in the data: \n",
      "    # get their ratings \n",
      "    for ratings in self.data.values(): \n",
      "        # for each item & rating in that set of ratings: \n",
      "        for (item, rating) in ratings.items(): \n",
      "            self.frequencies.setdefault(item, {}) \n",
      "            self.deviations.setdefault(item, {}) \n",
      "            # for each item2 & rating2 in that set of ratings: \n",
      "            for (item2, rating2) in ratings.items(): \n",
      "                if item != item2: \n",
      "                    # add the difference between the ratings \n",
      "                    # to our computation \n",
      "                    self.frequencies[item].setdefault(item2, 0) \n",
      "                    self.deviations[item].setdefault(item2, 0.0) \n",
      "                    self.frequencies[item][item2] += 1\n",
      "                    self.deviations[item][item2] += rating - rating2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code added in this step computes the difference between two ratings and adds that to the \n",
      "self.deviations running sum. Again, using the data:\n",
      "{\"Taylor Swift\": 4, \"PSY\": 3, \"Whitney Houston\": 4}\n",
      "when we are in the outer loop where item = \u201cTaylor Swift\u201d and rating = 4 and in the inner \n",
      "loop where item2 = \u201cPSY\u201d and rating2 = 3 the last line of the code above adds 1 to \n",
      "self.deviations[\u201cTaylor Swift\u201d][\u201cPSY\u201d]."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Step 4:\n",
      "Finally, we need to iterate through self.deviations to divide each deviation by its associated \n",
      "frequency."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeDeviations(self):\n",
      "    # for each person in the data:\n",
      "    # get their ratings\n",
      "    for ratings in self.data.values():\n",
      "        # for each item & rating in that set of ratings:\n",
      "        for (item, rating) in ratings.items():\n",
      "            self.frequencies.setdefault(item, {})\n",
      "            self.deviations.setdefault(item, {}) \n",
      "            # for each item2 & rating2 in that set of ratings:\n",
      "            for (item2, rating2) in ratings.items():\n",
      "                if item != item2:\n",
      "                    # add the difference between the ratings \n",
      "                    # to our computation\n",
      "                    self.frequencies[item].setdefault(item2, 0)\n",
      "                    self.deviations[item].setdefault(item2, 0.0)\n",
      "                    self.frequencies[item][item2] += 1\n",
      "                    self.deviations[item][item2] += rating - rating2\n",
      "                    for (item, ratings) in self.deviations.items():\n",
      "                        for item2 in ratings:\n",
      "                             ratings[item2] /= self.frequencies[item][item2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's it! Even with comments we implemented\n",
      "devi,j\n",
      "=\n",
      "ui\n",
      "\u2212uj\n",
      "card(Si,j\n",
      "(X))\n",
      "u\u2208Si,j\n",
      "(X)\n",
      "\u2211\n",
      "in only 18 lines of code. Incredible!\n",
      "When I run this method on the data I have been using in this example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users2 = {\"Amy\": {\"Taylor Swift\": 4, \"PSY\": 3, \"Whitney Houston\": 4},\n",
      "\"Ben\": {\"Taylor Swift\": 5, \"PSY\": 2},\n",
      "\"Clara\": {\"PSY\": 3.5, \"Whitney Houston\": 4},\n",
      "\"Daisy\": {\"Taylor Swift\": 5, \"Whitney Houston\": 3}}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = recommender(users2)\n",
      "r.computeDeviations()\n",
      "r.deviations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'recommender' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-19-57969d17e643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeDeviations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeviations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'recommender' is not defined"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Weighted Slope 1: The recommendation component\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now it is time to code the recommendation component:\n",
      "P\n",
      "wS1\n",
      "(u)\n",
      "j\n",
      "=\n",
      "(devj,i\n",
      "+ui\n",
      "i\u2208S(u)\u2212{ j}\n",
      "\u2211 )cj,i\n",
      "cj,i\n",
      "i\u2208S(u)\u2212{ j}\n",
      "\u2211\n",
      "The big question I have is can we beat the 18 line implementation of computeDeviations. \n",
      "First, let's parse that formula and put it into English and/or pseudocode. You try:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def slopeOneRecommendations(self, userRatings):\n",
      " recommendations = {}\n",
      " frequencies = {}\n",
      "# for every item and rating in the user's recommendations\n",
      "for (userItem, userRating) in userRatings.items():\n",
      "# for every item in our dataset that the user didn't rate\n",
      "for (diffItem, diffRatings) in self.deviations.items():\n",
      "if diffItem not in userRatings and \\\n",
      " userItem in self.deviations[diffItem]:\n",
      " freq = self.frequencies[diffItem][userItem]\n",
      " recommendations.setdefault(diffItem, 0.0)\n",
      " frequencies.setdefault(diffItem, 0)\n",
      "# add to the running sum representing the numerator\n",
      "# of the formula\n",
      " recommendations[diffItem] += (diffRatings[userItem] +\n",
      " userRating) * freq\n",
      "# keep a running sum of the frequency of diffitem\n",
      " frequencies[diffItem] += freq\n",
      " recommendations = [(self.convertProductID2name(k),\n",
      " v / frequencies[k])\n",
      "for (k, v) in recommendations.items()]\n",
      "# finally sort and return\n",
      " recommendations.sort(key=lambda artistTuple: artistTuple[1],\n",
      " reverse = True)\n",
      "return recommendations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-20-16c5ced2f2a5>, line 7)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> r = recommender(users2)\n",
      ">>> r.computeDeviations()\n",
      ">>> g = users2['Ben']\n",
      ">>> r.slopeOneRecommendations(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'recommender' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-21-c3752f4743cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeDeviations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ben'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslopeOneRecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'recommender' is not defined"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "This results matches what we calculated by hand. So the recommendation part of the \n",
      "algorithm weighs in at 18 lines. So in 36 lines of Python code we implemented the Slope One \n",
      "algorithm. With Python you can write pretty compact code."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-22-ecbfd6f3a348>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-ecbfd6f3a348>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This results matches what we calculated by hand. So the recommendation part of the\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###MovieLens data set\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try out the Slope One recommender on a different dataset. The MovieLens dataset\u2014\n",
      "collected by the GroupLens Research Project at the University of Minnesota\u2014contains user \n",
      "ratings of movies. The data set is available for download at www.grouplens.org. The data set \n",
      "is available in three sizes; for the demo here I \n",
      "am using the smallest one which contains \n",
      "100,000 ratings (1-5) from 943 users on 1,682 \n",
      "movies. I wrote a short function that will \n",
      "import this data into the recommender class.\n",
      "Let's give it a try."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = recommender(0) \n",
      "r.loadMovieLens('/Users/raz/Downloads/ml-100k/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'recommender' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-4e3499890c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadMovieLens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/raz/Downloads/ml-100k/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'recommender' is not defined"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I will be using the info from User 1. Just to peruse the data, I will look at the top 50 items the \n",
      "user 1 rated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.computeDeviations() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.slopeOneRecommendations(r.data['1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'r' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-24-f75218e2063c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslopeOneRecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.slopeOneRecommendations(r.data['25'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'r' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-25-ba04e9350d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslopeOneRecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'25'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs \n",
      "from math import sqrt\n",
      "\n",
      "users2 = {\"Amy\": {\"Taylor Swift\": 4, \"PSY\": 3, \"Whitney Houston\": 4},\n",
      "          \"Ben\": {\"Taylor Swift\": 5, \"PSY\": 2},\n",
      "          \"Clara\": {\"PSY\": 3.5, \"Whitney Houston\": 4},\n",
      "          \"Daisy\": {\"Taylor Swift\": 5, \"Whitney Houston\": 3}}\n",
      "\n",
      "users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,\n",
      "                      \"Norah Jones\": 4.5, \"Phoenix\": 5.0,\n",
      "                      \"Slightly Stoopid\": 1.5, \"The Strokes\": 2.5,\n",
      "                      \"Vampire Weekend\": 2.0},\n",
      "         \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,\n",
      "                 \"Deadmau5\": 4.0, \"Phoenix\": 2.0,\n",
      "                 \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},\n",
      "         \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,\n",
      "                  \"Deadmau5\": 1.0, \"Norah Jones\": 3.0,\n",
      "                  \"Phoenix\": 5, \"Slightly Stoopid\": 1.0},\n",
      "         \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,\n",
      "                 \"Deadmau5\": 4.5, \"Phoenix\": 3.0,\n",
      "                 \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,\n",
      "                 \"Vampire Weekend\": 2.0},\n",
      "         \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,\n",
      "                    \"Norah Jones\": 4.0, \"The Strokes\": 4.0,\n",
      "                    \"Vampire Weekend\": 1.0},\n",
      "         \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,\n",
      "                     \"Norah Jones\": 5.0, \"Phoenix\": 5.0,\n",
      "                     \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,\n",
      "                     \"Vampire Weekend\": 4.0},\n",
      "         \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0,\n",
      "                 \"Norah Jones\": 3.0, \"Phoenix\": 5.0,\n",
      "                 \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},\n",
      "         \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,\n",
      "                      \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,\n",
      "                      \"The Strokes\": 3.0}\n",
      "        }\n",
      "\n",
      "\n",
      "\n",
      "class recommender:\n",
      "\n",
      "   def __init__(self, data, k=1, metric='pearson', n=5):\n",
      "      \"\"\" initialize recommender\n",
      "      currently, if data is dictionary the recommender is initialized\n",
      "      to it.\n",
      "      For all other data types of data, no initialization occurs\n",
      "      k is the k value for k nearest neighbor\n",
      "      metric is which distance formula to use\n",
      "      n is the maximum number of recommendations to make\"\"\"\n",
      "      self.k = k\n",
      "      self.n = n\n",
      "      self.username2id = {}\n",
      "      self.userid2name = {}\n",
      "      self.productid2name = {}\n",
      "      #\n",
      "      # The following two variables are used for Slope One\n",
      "      # \n",
      "      self.frequencies = {}\n",
      "      self.deviations = {}\n",
      "      # for some reason I want to save the name of the metric\n",
      "      self.metric = metric\n",
      "      if self.metric == 'pearson':\n",
      "         self.fn = self.pearson\n",
      "      #\n",
      "      # if data is dictionary set recommender data to it\n",
      "      #\n",
      "      if type(data).__name__ == 'dict':\n",
      "         self.data = data\n",
      "\n",
      "   def convertProductID2name(self, id):\n",
      "      \"\"\"Given product id number return product name\"\"\"\n",
      "      if id in self.productid2name:\n",
      "         return self.productid2name[id]\n",
      "      else:\n",
      "         return id\n",
      "\n",
      "\n",
      "   def userRatings(self, id, n):\n",
      "      \"\"\"Return n top ratings for user with id\"\"\"\n",
      "      print (\"Ratings for \" + self.userid2name[id])\n",
      "      ratings = self.data[id]\n",
      "      print(len(ratings))\n",
      "      ratings = list(ratings.items())[:n]\n",
      "      ratings = [(self.convertProductID2name(k), v)\n",
      "                 for (k, v) in ratings]\n",
      "      # finally sort and return\n",
      "      ratings.sort(key=lambda artistTuple: artistTuple[1],\n",
      "                   reverse = True)      \n",
      "      for rating in ratings:\n",
      "         print(\"%s\\t%i\" % (rating[0], rating[1]))\n",
      "\n",
      "\n",
      "   def showUserTopItems(self, user, n):\n",
      "      \"\"\" show top n items for user\"\"\"\n",
      "      items = list(self.data[user].items())\n",
      "      items.sort(key=lambda itemTuple: itemTuple[1], reverse=True)\n",
      "      for i in range(n):\n",
      "         print(\"%s\\t%i\" % (self.convertProductID2name(items[i][0]),\n",
      "                           items[i][1]))\n",
      "            \n",
      "   def loadMovieLens(self, path=''):\n",
      "      self.data = {}\n",
      "      #\n",
      "      # first load movie ratings\n",
      "      #\n",
      "      i = 0\n",
      "      #\n",
      "      # First load book ratings into self.data\n",
      "      #\n",
      "      #f = codecs.open(path + \"u.data\", 'r', 'utf8')\n",
      "      f = codecs.open(path + \"u.data\", 'r', 'ascii')\n",
      "      #  f = open(path + \"u.data\")\n",
      "      for line in f:\n",
      "         i += 1\n",
      "         #separate line into fields\n",
      "         fields = line.split('\\t')\n",
      "         user = fields[0]\n",
      "         movie = fields[1]\n",
      "         rating = int(fields[2].strip().strip('\"'))\n",
      "         if user in self.data:\n",
      "            currentRatings = self.data[user]\n",
      "         else:\n",
      "            currentRatings = {}\n",
      "         currentRatings[movie] = rating\n",
      "         self.data[user] = currentRatings\n",
      "      f.close()\n",
      "      #\n",
      "      # Now load movie into self.productid2name\n",
      "      # the file u.item contains movie id, title, release date among\n",
      "      # other fields\n",
      "      #\n",
      "      #f = codecs.open(path + \"u.item\", 'r', 'utf8')\n",
      "      f = codecs.open(path + \"u.item\", 'r', 'iso8859-1', 'ignore')\n",
      "      #f = open(path + \"u.item\")\n",
      "      for line in f:\n",
      "         i += 1\n",
      "         #separate line into fields\n",
      "         fields = line.split('|')\n",
      "         mid = fields[0].strip()\n",
      "         title = fields[1].strip()\n",
      "         self.productid2name[mid] = title\n",
      "      f.close()\n",
      "      #\n",
      "      #  Now load user info into both self.userid2name\n",
      "      #  and self.username2id\n",
      "      #\n",
      "      #f = codecs.open(path + \"u.user\", 'r', 'utf8')\n",
      "      f = open(path + \"u.user\")\n",
      "      for line in f:\n",
      "         i += 1\n",
      "         fields = line.split('|')\n",
      "         userid = fields[0].strip('\"')\n",
      "         self.userid2name[userid] = line\n",
      "         self.username2id[line] = userid\n",
      "      f.close()\n",
      "      print(i)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   def loadBookDB(self, path=''):\n",
      "      \"\"\"loads the BX book dataset. Path is where the BX files are\n",
      "      located\"\"\"\n",
      "      self.data = {}\n",
      "      i = 0\n",
      "      #\n",
      "      # First load book ratings into self.data\n",
      "      #\n",
      "      f = codecs.open(path + \"u.data\", 'r', 'utf8')\n",
      "      for line in f:\n",
      "         i += 1\n",
      "         # separate line into fields\n",
      "         fields = line.split(';')\n",
      "         user = fields[0].strip('\"')\n",
      "         book = fields[1].strip('\"')\n",
      "         rating = int(fields[2].strip().strip('\"'))\n",
      "         if rating > 5:\n",
      "            print(\"EXCEEDING \", rating)\n",
      "         if user in self.data:\n",
      "            currentRatings = self.data[user]\n",
      "         else:\n",
      "            currentRatings = {}\n",
      "         currentRatings[book] = rating\n",
      "         self.data[user] = currentRatings\n",
      "      f.close()\n",
      "      #\n",
      "      # Now load books into self.productid2name\n",
      "      # Books contains isbn, title, and author among other fields\n",
      "      #\n",
      "      f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')\n",
      "      for line in f:\n",
      "         i += 1\n",
      "         # separate line into fields\n",
      "         fields = line.split(';')\n",
      "         isbn = fields[0].strip('\"')\n",
      "         title = fields[1].strip('\"')\n",
      "         author = fields[2].strip().strip('\"')\n",
      "         title = title + ' by ' + author\n",
      "         self.productid2name[isbn] = title\n",
      "      f.close()\n",
      "      #\n",
      "      #  Now load user info into both self.userid2name and\n",
      "      #  self.username2id\n",
      "      #\n",
      "      f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')\n",
      "      for line in f:\n",
      "         i += 1\n",
      "         # separate line into fields\n",
      "         fields = line.split(';')\n",
      "         userid = fields[0].strip('\"')\n",
      "         location = fields[1].strip('\"')\n",
      "         if len(fields) > 3:\n",
      "            age = fields[2].strip().strip('\"')\n",
      "         else:\n",
      "            age = 'NULL'\n",
      "         if age != 'NULL':\n",
      "            value = location + '  (age: ' + age + ')'\n",
      "         else:\n",
      "            value = location\n",
      "         self.userid2name[userid] = value\n",
      "         self.username2id[location] = userid\n",
      "      f.close()\n",
      "      print(i)\n",
      "                \n",
      "        \n",
      "   def computeDeviations(self):\n",
      "      # for each person in the data:\n",
      "      #    get their ratings\n",
      "      for ratings in self.data.values():\n",
      "         # for each item & rating in that set of ratings:\n",
      "         for (item, rating) in ratings.items():\n",
      "            self.frequencies.setdefault(item, {})\n",
      "            self.deviations.setdefault(item, {})                    \n",
      "            # for each item2 & rating2 in that set of ratings:\n",
      "            for (item2, rating2) in ratings.items():\n",
      "               if item != item2:\n",
      "                  # add the difference between the ratings to our\n",
      "                  # computation\n",
      "                  self.frequencies[item].setdefault(item2, 0)\n",
      "                  self.deviations[item].setdefault(item2, 0.0)\n",
      "                  self.frequencies[item][item2] += 1\n",
      "                  self.deviations[item][item2] += rating - rating2\n",
      "        \n",
      "      for (item, ratings) in self.deviations.items():\n",
      "         for item2 in ratings:\n",
      "            ratings[item2] /= self.frequencies[item][item2]\n",
      "\n",
      "\n",
      "   def slopeOneRecommendations(self, userRatings):\n",
      "      recommendations = {}\n",
      "      frequencies = {}\n",
      "      # for every item and rating in the user's recommendations\n",
      "      for (userItem, userRating) in userRatings.items():\n",
      "         # for every item in our dataset that the user didn't rate\n",
      "         for (diffItem, diffRatings) in self.deviations.items():\n",
      "            if diffItem not in userRatings and \\\n",
      "               userItem in self.deviations[diffItem]:\n",
      "               freq = self.frequencies[diffItem][userItem]\n",
      "               recommendations.setdefault(diffItem, 0.0)\n",
      "               frequencies.setdefault(diffItem, 0)\n",
      "               # add to the running sum representing the numerator\n",
      "               # of the formula\n",
      "               recommendations[diffItem] += (diffRatings[userItem] +\n",
      "                                             userRating) * freq\n",
      "               # keep a running sum of the frequency of diffitem\n",
      "               frequencies[diffItem] += freq\n",
      "      recommendations =  [(self.convertProductID2name(k),\n",
      "                           v / frequencies[k])\n",
      "                          for (k, v) in recommendations.items()]\n",
      "      # finally sort and return\n",
      "      recommendations.sort(key=lambda artistTuple: artistTuple[1],\n",
      "                           reverse = True)\n",
      "      # I am only going to return the first 50 recommendations\n",
      "      return recommendations[:50]\n",
      "        \n",
      "   def pearson(self, rating1, rating2):\n",
      "      sum_xy = 0\n",
      "      sum_x = 0\n",
      "      sum_y = 0\n",
      "      sum_x2 = 0\n",
      "      sum_y2 = 0\n",
      "      n = 0\n",
      "      for key in rating1:\n",
      "         if key in rating2:\n",
      "            n += 1\n",
      "            x = rating1[key]\n",
      "            y = rating2[key]\n",
      "            sum_xy += x * y\n",
      "            sum_x += x\n",
      "            sum_y += y\n",
      "            sum_x2 += pow(x, 2)\n",
      "            sum_y2 += pow(y, 2)\n",
      "      if n == 0:\n",
      "         return 0\n",
      "      # now compute denominator\n",
      "      denominator = sqrt(sum_x2 - pow(sum_x, 2) / n) * \\\n",
      "                    sqrt(sum_y2 - pow(sum_y, 2) / n)\n",
      "      if denominator == 0:\n",
      "         return 0\n",
      "      else:\n",
      "         return (sum_xy - (sum_x * sum_y) / n) / denominator\n",
      "\n",
      "\n",
      "   def computeNearestNeighbor(self, username):\n",
      "      \"\"\"creates a sorted list of users based on their distance\n",
      "      to username\"\"\"\n",
      "      distances = []\n",
      "      for instance in self.data:\n",
      "         if instance != username:\n",
      "            distance = self.fn(self.data[username],\n",
      "                               self.data[instance])\n",
      "            distances.append((instance, distance))\n",
      "      # sort based on distance -- closest first\n",
      "      distances.sort(key=lambda artistTuple: artistTuple[1],\n",
      "                     reverse=True)\n",
      "      return distances\n",
      "\n",
      "   def recommend(self, user):\n",
      "      \"\"\"Give list of recommendations\"\"\"\n",
      "      recommendations = {}\n",
      "      # first get list of users  ordered by nearness\n",
      "      nearest = self.computeNearestNeighbor(user)\n",
      "      #\n",
      "      # now get the ratings for the user\n",
      "      #\n",
      "      userRatings = self.data[user]\n",
      "      #\n",
      "      # determine the total distance\n",
      "      totalDistance = 0.0\n",
      "      for i in range(self.k):\n",
      "         totalDistance += nearest[i][1]\n",
      "      # now iterate through the k nearest neighbors\n",
      "      # accumulating their ratings\n",
      "      for i in range(self.k):\n",
      "         # compute slice of pie \n",
      "         weight = nearest[i][1] / totalDistance\n",
      "         # get the name of the person\n",
      "         name = nearest[i][0]\n",
      "         # get the ratings for this person\n",
      "         neighborRatings = self.data[name]\n",
      "         # get the name of the person\n",
      "         # now find bands neighbor rated that user didn't\n",
      "         for artist in neighborRatings:\n",
      "            if not artist in userRatings:\n",
      "               if artist not in recommendations:\n",
      "                  recommendations[artist] = neighborRatings[artist] * \\\n",
      "                                            weight\n",
      "               else:\n",
      "                  recommendations[artist] = recommendations[artist] + \\\n",
      "                                            neighborRatings[artist] * \\\n",
      "                                            weight\n",
      "      # now make list from dictionary and only get the first n items\n",
      "      recommendations = list(recommendations.items())[:self.n]\n",
      "      recommendations = [(self.convertProductID2name(k), v)\n",
      "                         for (k, v) in recommendations]\n",
      "      # finally sort and return\n",
      "      recommendations.sort(key=lambda artistTuple: artistTuple[1],\n",
      "                           reverse = True)\n",
      "      return recommendations\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}